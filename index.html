<html lang="en-GB">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Clarity: A Minimalist Website Template for AI Research</title>
    <meta name="description" content="We've presented Clarity, a minimalist and elegant website template for AI research.">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <meta name="robots" content="all">
    <meta content="en_EN" property="og:locale">
    <meta content="website" property="og:type">
    <meta content="https://shikun.io/projects/clarity" property="og:url">
    <meta content="Clarity" property="og:title">
    <meta content="Website Template for AI Research" property="og:description">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@your_twitter_id">
    <meta name="twitter:description" content="Clarity: A Minimalist Website Template for AI Research">
    <meta name="twitter:image:src" content="assets/figures/clarity.png">

    <link rel="stylesheet" type="text/css" media="all" href="assets/stylesheets/main_free.css" />
    <link rel="stylesheet" type="text/css" media="all" href="clarity/clarity.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/foundation.min.css">
    <link href="assets/fontawesome-free-6.6.0-web/css/all.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/styles.css"/>
    <script defer src="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/index.js"></script>
    <script src="assets/scripts/navbar.js"></script> <!-- Comment to remove table of content. -->
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            "HTML-CSS": {
              scale: 95,
              fonts: ["Gyre-Pagella"],
              imageFont: null,
              undefinedFamily: "'Arial Unicode MS', cmbright"
            },
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                processEscapes: true
              }
          });
    </script>
    <script type="text/javascript"
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
</head>

<body>
    <!-- Title Page -->
    <!-- Dark Theme Example: Change the background colour dark and change the following div "blog-title" into "blog-title white". -->
    <div class="container blog" id="first-content" style="background-color: #fcfbfa;">
        <!-- If you don't have a project cover: Change "blog-title" into "blog-title no-cover"  -->
        <div class="blog-title no-cover">
            <div class="blog-intro">
                <div>
                    <h1 class="title">Mocap Anywhere:<br>Towards Pairwise-Distance based Motion Capture in the Wild (for the Wild)</h1>
                    <!-- <p class="author">Ofir Abramovich, Ariel Shamir and Andreas Aristidou</p> -->
                    <br>
                    <p class="author" style="font-size: 20px;">
                        Ofir Abramovich <sup>1,2</sup>  Ariel Shamir <sup>1</sup> and Andreas Aristidou <sup>2,3</sup>
                    </p>
                    <p class="author" style="padding-top: 0px;">
                        <sup>1</sup> Reichman University <sup>2</sup> CYENS Institute <sup>3</sup> Cyprus University
                    </p>
                    <br>
                <div class="info">
                    <div>
                            <a href="https://arxiv.org" class="button icon" style="background-color: rgba(140, 140, 140, 0.2)"> Paper <i class="fa-solid fa-book-open"></i></a> &nbsp;&nbsp; 
                            <a href="https://github.com/ofir1080/WildPoser" class="button icon" style="background-color: rgba(140, 140, 140, 0.2)">Code <i class="fa-solid fa-code"></i></a>  &nbsp;&nbsp; 
                            <a href="#project-video" class="button icon" style="background-color: rgba(140, 140, 140, 0.2);">Video <i class="fa-regular fa-file-video"></i></a> &nbsp;&nbsp;
                            <!-- <a href="https://huggingface.co/spaces/" class="button icon" style="background-color: rgba(255, 255, 255, 0.2)">Demo <i class="fa-solid fa-laptop-code"></i></a>  -->
                        </div>
                    </div>
                    <br>
                    <div class="info">
                        <div>
                            <img src="assets/ma_walking.gif" alt="Walking Animation" style="width: 100%; max-width: 600px;">
                        </div>
                    </div>

                    <br>
                    <div>
                        <p class="abstract">
                        <h2>Abstract</h2>
                            <p>
                                We introduce a novel motion capture system that reconstructs full-body 3D motion using only sparse pairwise distance (PWD) measurements from body-mounted(UWB) sensors. Using time-of-flight ranging between wireless nodes, our method eliminates the need for external cameras, enabling robust operation in uncontrolled and outdoor environments. Unlike traditional optical or inertial systems, our approach is shape-invariant and resilient to environmental constraints such as lighting and magnetic interference.
                            </p>
                        <p>
                            At the core of our system is <b>Wild-Poser</b> (WiP for short), a compact, real-time Transformer-based architecture that directly predicts 3D joint positions from noisy or corrupted PWD measurements, which can later be used for joint rotation reconstruction via learned methods. WiP generalizes across subjects of varying morphologies, including non-human species, without requiring individual body measurements or shape fitting. Operating in real time, WiP achieves low joint position error and demonstrates accurate 3D motion reconstruction for both human and animal subjects in-the-wild. Our empirical analysis highlights its potential for scalable, low-cost, and general purpose motion capture in real-world settings.
                        </p>
                   </div>
                </div>
               
            </div>

        </div>
    </div>


    <div class="container blog main">
        <h2>
            Method
        </h2>

            <img src="assets/model_v11.png">
            <img src="assets/method_cap.png">
            <!-- <p class="caption">
                Erat id non venenatis nullam leo nisl risus fames. Quis montes tortor aenean posuere non. Maximus dui cras enim tristique; ipsum pellentesque ut. Mauris hac felis elit scelerisque nascetur risus adipiscing ultrices. Quis augue pulvinar laoreet facilisis vel. Pharetra blandit nunc id, sem cubilia sit porttitor. Montes hendrerit vestibulum vulputate tincidunt facilisis metus. Interdum mi vivamus nunc consectetur adipiscing; aptent semper dictum.
            </p> -->
    </div>

    <div class="container blog main gray">
        <h2>
            Motion Capture For the Wild
        </h2>
        <img src="assets/animals.png">
        <p class="text">
            We evaluate our method on both synthetic and real-world datasets, demonstrating its effectiveness in reconstructing accurate 3D poses from sparse pairwise distance measurements. Our results show that WiP outperforms existing methods in terms of joint position accuracy and robustness to noise and occlusions.
        </p>

    </div>

    <div class="container blog main">
        <h2>
            Comparison
        </h2>
        <h4>
            End-Effector Error Comparison
        </h4>
                <div class="columns-2">
                    <img src="assets/ee_comp.png" style="width: 90%;">
                    <img src="assets/ee_comp_2.png" style="height: 100%;">
                </div>
        <p class="caption">
            <br>
                    Fig. 8: Our method (blue) produces poses where the end-effectors (darker shades) align more closely with the original sensor target positions (green spheres), compared to UIP (magenta) and PIP (yellow).
        </p>
    </div>
    <div class="container blog main">
        <h4>
            Commulative Global Drift
        </h4>
        <img src="assets/plots.png">
        <p class="caption"> 
                Unlike inertial-based methods, our approach is robust to cumulative error, both in time (left) and distance (right). By utilizing distance measurements and incorporating additional reference sensors as anchors, we can estimate the global position of the subject at every timestamp with minimal reliance on previous predictions.
        </p>

    </div>

    <div class="container blog main gray">
        <h2>
            Cite Us
        </h2>
        <p class="text">
            If you find our work useful in your research, please consider citing:
        <pre>
            <code class="plaintext">@article{lecun2015deep,
    title={Deep learning},
    author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
    journal={nature},
    year={2015},
    publisher={Nature Publishing Group UK London}
    }</code>
        </pre>
        </p>
    <img src="assets/hello_vis.png" style="width: 100%;">
    </div>


    <!-- Footer Page -->
    <footer>
        <div class="container">
            <p>
                This website is built on the <a href="https://shikun.io/projects/clarity">Clarity Template</a>, designed by <a href="https://shikun.io/">Shikun Liu</a>.
            </p>
        </div>    
    </footer>
    

    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
    <script src="clarity/clarity.js"></script>    
    <script src="assets/scripts/main.js"></script>    
    </html>
</body>